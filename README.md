# Repo Overview
## This repository contains implementations of linear regression and backpropagation algorithms from scratch in Python. The goal is to demonstrate fundamental machine-learning concepts and techniques without relying on high-level libraries.

# Explanation
## Linear Regression Implementation:
### Explaining the scaling of the data process and how it can help either in faster learning time or stabilize the values.
### An implementation of linear regression model using only numpy.
![alt text](https://github.com/MAAF1/Educational-some-ML-algorithms-from-scratch/blob/main/linearform11.png)
### fully low-level explanation of the learning process (gradient descent) and how to optimize the parameters
![alt text](https://github.com/MAAF1/Educational-some-ML-algorithms-from-scratch/blob/main/gradient_descent_parameter_a.gif)
### Calculate the cost using MSE to make sure you select the optimized hyperparameters.
![alt text](https://github.com/MAAF1/Educational-some-ML-algorithms-from-scratch/blob/main/costform.png)
# Backpropagation Implementation (Iterative approach):
## Feed-forward neural network structure with a simple 2 layers network 
## Forward propagation and backward error propagation algorithms
## Computing gradients of the network 
## Updating weights function 
# Further additions:
## Adding prediction function to the linear regression notebook 
## Adding gradient descent to Neural Network file with the prediction function (you can check my repo for these two using the vectorized approach for NN)
